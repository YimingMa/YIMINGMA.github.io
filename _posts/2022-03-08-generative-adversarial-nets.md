---
key: 2022_03_08_01
title: Introduction to Generative Adversarial Networks
tags: ["Computer Vision", "Self-Supervised Learning"]
mathjax: true
mathjax_autoNumber: true
author: Yiming
comment: false
pageview: false
aside:
    toc: true
---

> This post refers to many materials of [Understanding Generative Adversarial Networks (GANs)](https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29) by Joseph Rocca and Baptiste Rocca. The original paper in which GANs are proposed is called *Generative Adversarial Nets* by Ian Goodfellow et al.

## Introduction

Yann LeCun described it as "the most interesting idea in the last 10 years in Machine Learning". Of course, such a compliment coming from such a prominent researcher in the deep learning area is always a great advertisement for the subject we are talking about! And, indeed, **Generative Adversarial Networks** (**GANs** for short) have had a huge success since they were introduced in 2014 by Ian J. Goodfellow and co-authors in the article [Generative Adversarial Nets](https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf).

Before going into the details, let's give a quick overview of what GANs are made for. Generative adversarial networks belong to the set of **generative** models, which are able to generate new content. To illustrate this notion of "generative models", we can take a look at some well known examples of results obtained with GANs.

<figure>
  <img src="/posts.assets/2022-03-08-generative-adversarial-nets.assets/visualisations.png" alt="visualisations" style="width:100%">
  <figcaption>Illustration of GANs abilities by Ian Goodfellow and co-authors. These images are samples generated by GANs after training on two datasets: MNIST and TFD. For both, the rightmost column contains real images in the training set that are the nearest from the direct neighbouring generated samples. The comparison between them show that the produced data are really generated and not only memorised by the network.</figcaption>
</figure>

## Sampling from Distributions

In this section, we discuss the process of generating random numbers: we review some existing methods and more especially the inverse transform method that draws samples from complicated distributions based on the uniform distribution. Although all this could seems a little bit far from our subject of matter, GANs, we will see in the next section the deep link that exists with generative models.

### Uniform Random Numbers

Computers are fundamentally deterministic, so theoretically, it is impossible to generate numbers that are really random. However, numbers generated by certain algorithms do share similar properties of theoretical random numbers. <span style="color:Coral;">In particular, a computer is able to generate a sequence of numbers that approximatively follows the uniform distribution between 0 and 1, by using a pseudorandom number generator</span>. The uniform case is a very simple one upon which more complex distributions can be sampled in different ways.

### The Inverse Transform Method

Let $$X$$ be a random variable with the cumulative distribution function $$F_X( \cdot )$$, and we would like to draw samples from this distribution. Let $$U$$ be a uniform random variable over $$[0, \; 1]$$, and we know its CDF can be expressed as

$$F_U(x) = \mathbb{P}(U \le x) = x. \notag$$

For simplicity, we suppose that the function $$F_X$$ is invertible and its inverse is denoted as $$F_X^{-1}$$. (If $$F_X$$ is not invertible, then we can modify the pseudo-inverse’s values on a zero-measure subset to make it a proper function.) Then we have $$Y := F_X(X) \sim U(0, \; 1)$$, because

$$
\begin{align*}
F_Y(x) & = \mathbb{P}\left( Y \le x\right) \\
& = \mathbb{P}\left( F_X(X) \le x \right) \\
& = \mathbb{P}\left( X \le F_X^{-1}(x) \right) \quad (\text{since $F_X$ is invertible)} \\
& = F_X \left( F_X^{-1} (x) \right) \\
& = x
\end{align*}
$$

Thus, to sample from the distribution of $$X$$, we can first draw samples $$\{ u_1, \, u_2, \, \cdots, u_n\}$$ from $$U(0, \; 1)$$, then transform them with the inverse $$F_X^{-1}$$:

$$
\left\{ F_X^{-1} (u_1), \, F_X^{-1} (u_2), \, \cdots, F_X^{-1} (u_n) \right\}. \notag
$$

To summarise, the inverse transform method is a way to generate samples of a distribution that leverages uniform random numbers going through a well designed "transform function" (the inverse CDF). This notion can be extended to a more generalised idea, in which complicated random variables can be expressed as some simpler random variables (not necessarily uniform and then the transform functions are no longer the inverse CDF). Conceptually, the purpose of the "transform function" is to deform/reshape the initial probability distribution: the transform function takes from where the initial distribution is too high compared to the targeted distribution and puts it where it is too low.

<figure>
  <img src="/posts.assets/2022-03-08-generative-adversarial-nets.assets/inverse_transform_method.png" alt="visualisations" style="width:100%">
  <figcaption>Illustration of the inverse transform method. In blue: the uniform distribution over [0,1]. In orange: the the standard Gaussian distribution. In grey: the mapping from the uniform to the gaussian distribution (inverse CDF).</figcaption>
</figure>

## Generative Models

### Problem Formulation

Suppose that we are interested in generating black and white square images of dogs with the size of $$n$$ by $$n$$ pixels. We can reshape each image as an $$N = n \times n$$ dimensional vector.  However, it doesn’t mean that all $$N$$-dimensional vectors represent dogs once shaped back to a square! So, we can say that only some $$N$$-dimensional vectors are associated with images of dogs, and they follow certain distribution over the $$N$$-dimensional vector space. In the same spirit, there exist, over this $$N$$-dimensional vector space, probability distributions for images of cats, birds and so on.

<p style="color:Crimson;">Then, the problem of generating a new image of dog is equivalent to the problem of generating a new vector following the "dog probability distribution" over the $N$-dimensional vector space. So we are, in fact, facing a problem of sampling a random variable with respect to a specific probability distribution.</p>

At this point, we can mention two important issues. First the "dog probability distribution" we mentioned is a very complex distribution over a very large space. Second, even if we can assume the existence of such underlying distribution (there actually exist images that look like dogs and others that don’t), we obviously don’t know how to express it explicitly. These two problems mean that we can’t directly utilise classic sampling approaches, such as the inverse transform method.

### Fit the "Inverse Transform Function"

Suppose the random vector of dogs' images, denoted by $$\boldsymbol{X} \in \mathbb{R}^N$$, can be expressed as a function of an $$N$$-dimensional uniform random vector. Thus, to generate a new dog image, we only need to draw a sample from the $$N$$-dimensional uniform distribution and feed it to the function to acquire an observation of $$\boldsymbol{X}$$. Finally, we reshape the vector into a desired $$n \times n$$ image. However, due to the extremely complicated form of the transform function (the close form may even not exist), we have to use neural networks to fit the inverse.

<figure>
  <img src="/posts.assets/2022-03-08-generative-adversarial-nets.assets/generative_models.png" alt="visualisations" style="width:100%">
  <figcaption>Illustration of the notion of generative models using neural networks. Obviously, the dimensionality we are really talking about are much higher than represented here.</figcaption>
</figure>

## Generative Matching Networks

> **Disclaimer**: The denomination of "Generative Matching Networks" is not a standard one. However, we can find in the literature, for example, "Generative Moments Matching Networks" or also "Generative Features Matching Networks". We just want here to use a slightly more general denomination for what we describe bellow.

### Training Generative models

So far, we have shown that our problem of generating a new image of a dog can be rephrased into a problem of generating a random vector in the $$N$$-dimensional vector space that follows the "dog probability distribution". We have also suggested that the random vector can be generated via the transform method, with a neural network modelling the transform function.

Now, we still need to train (optimise) the network to express the right transform function. To this purpose, we can suggest two different training methods: a direct one and an indirect one.

- <span style="color:RoyalBlue;">In the direct training method, there are predefined metrics estimating the distance between the ground-truth distribution and the generated one, so that the error can be directly back-propagated through the network. This is the idea that rules Generative Matching Networks (GMNs).<span>
- <span style="color:RoyalBlue;">In the indirect training method, we do not defined metrics for distribution distances. Instead, we also train a downstream network which differentiates samples from the ground-truth distribution and those from the generated distribution. The optimisation process of the overall network with respect to the downstream task will enforce the generated distribution to be close to the true distribution. This idea is the one behind Generative Adversarial Networks (GANs).<span>

But for now, let's start with the direct method and GMNs.

### Distance of Two Probability Distributions Based on Samples

As mentioned, the idea of GMNs is to train the generative network by directly comparing the generated distribution with the true one. However, we do not know how to express them explicitly, so comparisons based on explicit expressions are not possible. On the other hand,  we can estimate the distance between distributions based on samples. Indeed, we have a sample of real dog images, and we can produce a sample of generated data at each iteration of the training process.

In theory, any distance (or similarity measure) able to compare effectively two distributions based on samples can be used, and here we exploit the **Maximum Mean Discrepancy** (**MMD**) approach. Although it is not fully out of the scope of this article, we have decided not to spend much more time describing the MMD. The readers that would like to know more about MMD right now can refer to [these slides](http://www.gatsby.ucl.ac.uk/~gretton/papers/testing_workshop.pdf), [this article](http://www.gatsby.ucl.ac.uk/~gretton/papers/GreBorRasSchSmo07.pdf) or [this article](http://www.jmlr.org/papers/volume13/gretton12a/gretton12a.pdf).

### Back Propagation of MMD

So, once we have defined a metric to estimate the distance between two distributions based on samples, we can design the training process of the generative network in GMNs. Given samples from the $$N$$-dimensional uniform distribution as input, we would like the probability distribution of the generated output to follow the "dog probability distribution". The idea of GMNs is then to optimise the network by repeating the following steps:

1. Generate some $$N$$-dimensional vectors that follow the uniform distribution.
2. Feed these vectors to the network and collect the generated output vectors, which are the generated dog vectors.
3. Estimate the distance between distributions based on the real dog data with the generated ones by some metrics (e.g., MMD).
4. Use back propagation to make one step of gradient descent to lower the distance (e.g., MMD) between true and generated distributions

As written above, when following these steps we are applying a gradient descent over the network with a loss function that is the distance between the true and the generated distributions at the current iteration.

<figure>
  <img src="/posts.assets/2022-03-08-generative-adversarial-nets.assets/GMN.png" alt="visualisations" style="width:100%">
  <figcaption>Generative matching networks take simple random inputs, generate new data, directly compare the distribution of the generated data to the distribution of the true data and backpropagate the matching error to train the network. In short, it tries to fit the transform function.</figcaption>
</figure>

## Generative Adversarial Networks

### The "Indirect" Training Method

During training, GMNs compare the distribution of generated samples with that of the ground-truth samples directly, since we are using some pre-defined methods to estimate the distance between distributions based on samples. GANs instead replace these sample-based metrics by a downstream task. Since our goal is to generate a dog image that looks like real images, the downstream task is to discriminate between the real ones and synthesised ones. Or, we could say a “non-discrimination” task as we want the discrimination to fail as much as possible. <span style="color:RoyalBlue;">So, in a GAN architecture, we have a **discriminator**, that takes samples of true and generated data and that try to classify them as well as possible, and a **generator** that is trained to fool the discriminator as much as possible.</span> Let’s see on a simple example why the direct and indirect approaches we mentioned should, in theory, lead to the same optimal generator.

### The Ideal Case: Perfect Generator and Discriminator

In order to better understand why training a generator to fool a discriminator will lead to the same result as training directly the generator to match the target distribution, let's take a simple one dimensional example. We forget, for the moment, how both generator and discriminator are represented and consider them as abstract notions. Moreover, both are supposed to be "perfect" (with infinite capacities) in the sense that they are not constrained by any kind of (parametrised) model.

Suppose that we have a ground-truth distribution, for example a 1-D Gaussian and that we want a generator that samples from this probability distribution. In the "direct" method GMNs, the generator is iteratively adjusted to correct the measured distance between the true and the generated distributions. If we assume that the optimisation process is perfect, then theoretically, the generated distribution in the end should exactly match the true one.

<figure>
  <img src="/posts.assets/2022-03-08-generative-adversarial-nets.assets/direct_matching_method.png" alt="Direct Matching Method" style="width:100%">
  <figcaption>Illustration of the concept of "direct" matching method. The distribution in blue is the true one while the generated distribution is depicted in orange. Iteration by iteration, we compare the two distributions and adjust the networks weights through gradient descent steps. Here the comparison is done over the mean and the variance (similar to a truncated moments matching method). Notice that (obviously) this example is so simple that it doesn’t require an iterative approach: the purpose is only to illustrate the intuition given above.</figcaption>
</figure>

For the "indirect" approach, we have to consider also a discriminator. We assume for now that this discriminator is a kind of oracle that knows exactly what are the true and generated distribution and that is able, based on this information, to predict a class (`"true"` or `"generated"`) for any given sample point. If the two distributions are far apart, the discriminator will be able to classify most of the points we present to it easily and with a high level of confidence. If we want to fool the discriminator, we have to bring the generated distribution close to the true one. The discriminator then will have the most difficulty in predicting the class when the two distributions will be equal in all points: in this case, for each point there are equal chances for it to be `"true"` or `"generated"` and then the discriminator can't do better than being true in one case out of two in average.

<figure>
  <img src="/posts.assets/2022-03-08-generative-adversarial-nets.assets/indirect_matching_method.png" alt="Indirect Matching Method" style="width:100%">
  <figcaption>Intuition for the adversarial method. The blue distribution is the true one, the orange is the generated one. In grey, with corresponding y-axis on the right, we displayed the probability to be true for the discriminator if it chooses the class with the higher density in each point (assuming "true" and "generated" data are in equal proportions). The closer the two distributions are, the more often the discriminator is wrong. When training, the goal is to “move the green area” (generated distribution is too high) towards the red area (generated distribution is too low).</figcaption>
</figure>

At this point, it seems legitimate to wonder whether this indirect method is really a good idea.

- We have to optimise the generator based on a downstream task other than directly based on the estimation of distribution distances. However, estimating distribution distances based on samples is also computationally complex.
- Also, the indirect method requires a discriminator that we consider here as a given oracle but that is, in reality, neither known nor perfect. However, it can be learned!

### The Approximation: Adversarial Neural Networks

Let's now describe the specific forms that the generator and the discriminator in the GAN architecture take. The generator is a neural network that models a transform function. It takes a simple random vector (in our dog example a $N$-dimensional vector) as input and must return, once trained, another random vector that approximately follows the targeted distribution. As we choose to use learn to differentiate between the true and the generated distributions, the discriminator is modelled by another neural network. It takes a random vector (either generated or from a real image) as input and returns the probability of this point to be a "true" one as output.

Notice that the fact that we impose now parametrised models to express both the generator and the discriminator (instead of the idealised versions in the previous subsection) has, in practice, no huge impact on the theoretical argument/intuition given above. We just then work in some parametrised spaces instead of ideal full spaces, so the optimal points that we should reach in the ideal case can then be seen as "rounded" by the precision capacity of the parametrised models.

Once defined, the two networks can then be trained jointly (at the same time) with opposite goals:

- The goal of the generator is to fool the discriminator. Thus, the generative neural network is trained to maximise the final classification error (between true and generated data), so that the discriminator confuses between true images and generated ones.
- The goal of the discriminator is to detect fake generated data, so the discriminative neural network is trained to minimise the final classification error.

So, at each iteration of the training process, the weights of the generative network are updated in order to increase the classification error (error gradient ascent over the generator's parameters) whereas the weights of the discriminative network are updated so that to decrease this error (error gradient descent over the discriminator's parameters).

<figure>
  <img src="/posts.assets/2022-03-08-generative-adversarial-nets.assets/GAN.png" alt="GAN" style="width:100%">
  <figcaption>Generative Adversarial Networks representation. The generator takes simple random variables as inputs and generate new data. The discriminator takes "true" and "generated" data and try to discriminate them, building a classifier. The goal of the generator is to fool the discriminator (increase the classification error by mixing up as much as possible generated data with true data) and the goal of the discriminator is to distinguish between true and generated data.</figcaption>
</figure>

These opposite goals and the adversarial training of the two networks explain the name of “adversarial networks”: both networks try to beat each other and, doing so, they are both becoming better and better. The competition between them makes these two networks “progress” with respect to their respective goals. From a game-theory point of view, we can think of this setting as a minimax two-players game where the equilibrium state corresponds to the situation where the generator produces data from the exact targeted distribution and where the discriminator predicts “true” or “generated” with probability $\frac{1}{2}$ for any point it receives.

> **Note**: This section is a little bit more technical and not absolutely necessary for the overall understanding of GANs. So, the readers that don’t want to read some mathematics right now can skip this section for the moment. For the others, let’s see how the intuitions given above are mathematically formalised.
> **Disclaimer**: The equations in the following are not the ones of the article of Ian Goodfellow. We propose here an other mathematical formalisation for two reasons: first, to stay a little bit closer to the intuitions given above and, second, because the equations of the original paper are already so clear that it would not have been useful to just rewrite them. Notice also that we absolutely do not enter into the practical considerations (vanishing gradient or other) related to the different possible loss functions. We highly encourage the reader to also take a look at the equations of the original paper: the main difference is that Ian Goodfellow and co-authors have worked with cross-entropy error instead of absolute error (as we do bellow). Moreover, in the following we assume a generator and a discriminator with unlimited capacity.

Neural network models essentially require to define two things: an architecture and a loss function. We have already described the architecture of GANs. It comprises two networks:

- <span style="color:RoyalBlue;">A **generative network** $\boldsymbol{G}(\cdot)$ that takes a random vector $\boldsymbol{z}$ with density $p_{\boldsymbol{z}}$ as input and returns an output $\boldsymbol{x}_g = G ( \boldsymbol{z})$ that should approximately follow (after training) the targeted probability distribution.</span>
- <span style="color:RoyalBlue;">A **discriminative network** $D(\cdot) $ that takes an input $\boldsymbol{x}$ that can be a “true” one ($\boldsymbol{x}_t$, whose density is denoted by $p_t$) or a “generated” one ($\boldsymbol{x}_g$, whose density $p_g$ is the density induced by the density $p_{\boldsymbol{z}}$ going through $\boldsymbol{G}$) and that returns the probability $D(\boldsymbol{x})$ of $\boldsymbol{x}$ to be a “true” sample.</span>

During each iteration:

1. Randomly select a real dog image $\boldsymbol{x}_t$.
2. Generate a random vector $\boldsymbol{z}$, and derive $\boldsymbol{x}_g$ via the “transform function” $\boldsymbol{G}$:
    $$
    \boldsymbol{x}_g: =\boldsymbol{G}(\boldsymbol{z})
    $$
3. Feed both $\boldsymbol{x}_t$ and $\boldsymbol{x}_g$ to the discriminative network $D$.
4. Calculate the loss function:
    $$
    \left( 1 - D(\boldsymbol{x}_t) \right) + D(\boldsymbol{x}_g) = \left( 1 - D(\boldsymbol{x}_t) \right) + D \left( \boldsymbol{G}(\boldsymbol{z}) \right)
    $$
    For $D$, we expect it to classify $\boldsymbol{x}_t$ to as “true” and $\boldsymbol{x}_g$ as “generated”, so we expect $D(\boldsymbol{x}_t) \approx 1$ and $D(\boldsymbol{x}_g) \approx 0$.
5. Optimisation:
    $$
    \max_{\boldsymbol{G}}\min_{D} \left[ \left( 1 - D(\boldsymbol{x}_t) \right) + D \left( \boldsymbol{G}(\boldsymbol{z}) \right) \right].
    $$
    - Minimise the loss function with respect to $D$: $D(\boldsymbol{x}_t) \to 1$ and $D (\boldsymbol{G}(\boldsymbol{z})) \to 0$, i.e., both “true” and “generated” data can be classified correctly.
    - Maximise the loss function with respect to $\boldsymbol{G}$: $D (\boldsymbol{G}(\boldsymbol{z})) \to 1$, i.e., the discriminator regards the “generated” data as “true”, which means the generated distribution is very similar to the true one.
