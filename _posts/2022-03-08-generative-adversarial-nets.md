---
key: 2022_03_08_01
title: Introduction to Generative Adversarial Networks
tags: ["Computer Vision", "Self-Supervised Learning"]
mathjax: true
mathjax_autoNumber: true
author: Yiming
comment: false
pageview: false
aside:
    toc: true
---

**Claim**: This post refers to many materials of [Understanding Generative Adversarial Networks (GANs)](https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29) by Joseph Rocca and Baptiste Rocca. The original paper in which GANs are proposed is called *Generative Adversarial Nets* by Ian Goodfellow et al.

## Introduction

Yann LeCun described it as “the most interesting idea in the last 10 years in Machine Learning”. Of course, such a compliment coming from such a prominent researcher in the deep learning area is always a great advertisement for the subject we are talking about! And, indeed, **Generative Adversarial Networks** (**GANs** for short) have had a huge success since they were introduced in 2014 by Ian J. Goodfellow and co-authors in the article [Generative Adversarial Nets](https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf).

Before going into the details, let’s give a quick overview of what GANs are made for. Generative adversarial networks belong to the set of **generative** models, which are able to generate new content. To illustrate this notion of “generative models”, we can take a look at some well known examples of results obtained with GANs.

<figure>
  <img src="/posts.assets/2022-03-08-generative-adversarial-nets.assets/visualisations.png" alt="visualisations" style="width:100%">
  <figcaption>Illustration of GANs abilities by Ian Goodfellow and co-authors. These images are samples generated by GANs after training on two datasets: MNIST and TFD. For both, the rightmost column contains real images in the training set that are the nearest from the direct neighbouring generated samples. The comparison between them show that the produced data are really generated and not only memorised by the network.</figcaption>
</figure>

## Sampling from Distributions

In this section, we discuss the process of generating random numbers: we review some existing methods and more especially the inverse transform method that draws samples from complicated distributions based on the uniform distribution. Although all this could seems a little bit far from our subject of matter, GANs, we will see in the next section the deep link that exists with generative models.

### Uniform Random Numbers

Computers are fundamentally deterministic, so theoretically, it is impossible to generate numbers that are really random. However, numbers generated by certain algorithms do share similar properties of theoretical random numbers. <span style="color:Coral;">In particular, a computer is able to generate a sequence of numbers that approximatively follows the uniform distribution between 0 and 1, by using a pseudorandom number generator</span>. The uniform case is a very simple one upon which more complex distributions can be sampled in different ways.

### The Inverse Transform Method

Let $$X$$ be a random variable with the cumulative distribution function $$F_X( \cdot )$$, and we would like to draw samples from this distribution. Let $$U$$ be a uniform random variable over $$[0, \; 1]$$, and we know its CDF can be expressed as

$$F_U(x) = \mathbb{P}(U \le x) = x. \notag$$

For simplicity, we suppose that the function $$F_X$$ is invertible and its inverse is denoted as $$F_X^{-1}$$. (If $$F_X$$ is not invertible, then we can modify the pseudo-inverse’s values on a zero-measure subset to make it a proper function.) Then we have $$Y := F_X(X) \sim U(0, \; 1)$$, because

$$
\begin{align*}
F_Y(x) & = \mathbb{P}\left( Y \le x\right) \\
& = \mathbb{P}\left( F_X(X) \le x \right) \\
& = \mathbb{P}\left( X \le F_X^{-1}(x) \right) \quad (\text{since $F_X$ is invertible)} \\
& = F_X \left( F_X^{-1} (x) \right) \\
& = x
\end{align*}
$$

Thus, to sample from the distribution of $$X$$, we can first draw samples $$\{ u_1, \, u_2, \, \cdots, u_n\}$$ from $$U(0, \; 1)$$, then transform them with the inverse $$F_X^{-1}$$:

$$
\left\{ F_X^{-1} (u_1), \, F_X^{-1} (u_2), \, \cdots, F_X^{-1} (u_n) \right\}. \notag
$$

To summarise, the inverse transform method is a way to generate samples of a distribution that leverages uniform random numbers going through a well designed “transform function” (the inverse CDF). This notion can be extended to a more generalised idea, in which complicated random variables can be expressed as some simpler random variables (not necessarily uniform and then the transform functions are no longer the inverse CDF). Conceptually, the purpose of the “transform function” is to deform/reshape the initial probability distribution: the transform function takes from where the initial distribution is too high compared to the targeted distribution and puts it where it is too low.

<figure>
  <img src="/posts.assets/2022-03-08-generative-adversarial-nets.assets/inverse_transform_method.png" alt="visualisations" style="width:100%">
  <figcaption>Illustration of the inverse transform method. In blue: the uniform distribution over [0,1]. In orange: the the standard Gaussian distribution. In grey: the mapping from the uniform to the gaussian distribution (inverse CDF).</figcaption>
</figure>

## Generative Models

### Problem Formulation

Suppose that we are interested in generating black and white square images of dogs with the size of $$n$$ by $$n$$ pixels. We can reshape each image as an $$N = n \times n$$ dimensional vector.  However, it doesn’t mean that all $$N$$-dimensional vectors represent dogs once shaped back to a square! So, we can say that only some $$N$$-dimensional vectors are associated with images of dogs, and they follow certain distribution over the $$N$$-dimensional vector space. In the same spirit, there exist, over this $$N$$-dimensional vector space, probability distributions for images of cats, birds and so on.

<p style="color:Crimson;">Then, the problem of generating a new image of dog is equivalent to the problem of generating a new vector following the “dog probability distribution” over the $N$-dimensional vector space. So we are, in fact, facing a problem of sampling a random variable with respect to a specific probability distribution.</p>

At this point, we can mention two important issues. First the “dog probability distribution” we mentioned is a very complex distribution over a very large space. Second, even if we can assume the existence of such underlying distribution (there actually exist images that look like dogs and others that don’t), we obviously don’t know how to express it explicitly. These two problems mean that we can’t directly utilise classic sampling approaches, such as the inverse transform method.

### Fit the “Inverse Transform Function”

Suppose the random vector of dogs’ images, denoted by $$\boldsymbol{X} \in \mathbb{R}^N$$, can be expressed as a function of an $$N$$-dimensional uniform random vector. Thus, to generate a new dog image, we only need to draw a sample from the $$N$$-dimensional uniform distribution and feed it to the function to acquire an observation of $$\boldsymbol{X}$$. Finally, we reshape the vector into a desired $$n \times n$$ image. However, due to the extremely complicated form of the transform function (the close form may even not exist), we have to use neural networks to fit the inverse.

<figure>
  <img src="/posts.assets/2022-03-08-generative-adversarial-nets.assets/generative_models.png" alt="visualisations" style="width:100%">
  <figcaption>Illustration of the notion of generative models using neural networks. Obviously, the dimensionality we are really talking about are much higher than represented here.</figcaption>
</figure>

## Generative Matching Networks

**Disclaimer**: The denomination of “Generative Matching Networks” is not a standard one. However, we can find in the literature, for example, “Generative Moments Matching Networks” or also “Generative Features Matching Networks”. We just want here to use a slightly more general denomination for what we describe bellow.

### Training Generative models

So far, we have shown that our problem of generating a new image of a dog can be rephrased into a problem of generating a random vector in the $$N$$-dimensional vector space that follows the “dog probability distribution”. We have also suggested that the random vector can be generated via the transform method, with a neural network modelling the transform function.

Now, we still need to train (optimise) the network to express the right transform function. To this purpose, we can suggest two different training methods: a direct one and an indirect one.

- <span style="color:RoyalBlue;">In the direct training method, there are predefined metrics estimating the distance between the ground-truth distribution and the generated one, so that the error can be directly back-propagated through the network. This is the idea that rules Generative Matching Networks (GMNs).<span>
- <span style="color:RoyalBlue;">In the indirect training method, we do not defined metrics for distribution distances. Instead, we also train a downstream network which differentiates samples from the ground-truth distribution and those from the generated distribution. The optimisation process of the overall network with respect to the downstream task will enforce the generated distribution to be close to the true distribution. This idea is the one behind Generative Adversarial Networks (GANs).<span>

But for now, let’s start with the direct method and GMNs.

### Distance of Two Probability Distributions Based on Samples

As mentioned, the idea of GMNs is to train the generative network by directly comparing the generated distribution with the true one. However, we do not know how to express them explicitly, so comparisons based on explicit expressions are not possible. On the other hand,  we can estimate the distance between distributions based on samples. Indeed, we have a sample of real dog images, and we can produce a sample of generated data at each iteration of the training process.

In theory, any distance (or similarity measure) able to compare effectively two distributions based on samples can be used, and here we exploit the **Maximum Mean Discrepancy** (**MMD**) approach. Although it is not fully out of the scope of this article, we have decided not to spend much more time describing the MMD. The readers that would like to know more about MMD right now can refer to [these slides](http://www.gatsby.ucl.ac.uk/~gretton/papers/testing_workshop.pdf), [this article](http://www.gatsby.ucl.ac.uk/~gretton/papers/GreBorRasSchSmo07.pdf) or [this article](http://www.jmlr.org/papers/volume13/gretton12a/gretton12a.pdf).
